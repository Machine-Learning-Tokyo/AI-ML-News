# AlphaFold: a solution to a 50-year-old grand challenge in biology

- The latest version of AlphaFold (AlphaFold-2) has been recognised as a solution to one of biology's grand challenges - the “protein folding problem”. 

- It was validated at CASP14, the biennial Critical Assessment of protein Structure Prediction

- We’re excited about the potential impact AlphaFold may have on the future of biological research and scientific discovery. 

[<p align="center"> <img src="https://github.com/Machine-Learning-Tokyo/AI-ML-Newsletter/blob/master/images/alphafold.gif" width="600" /> </p>](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)

📌 Source: [DeepMind Blog](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)


# NeurIPS Meetup Japan 2020

- NeurIPS is one of the top conference for Machine Learning and Computational Neuroscience

- NeurIPS Meetup is a local event hosted during the NeurIPS conference, leveraging conference videos and live local content, with a duration ranging from a few hours to a full week, and bringing together participants from one or more companies, universities, and/or the public. 

- NeurIPS Meetup Japan will take place this year on December. 

- The NeurIPS Meetup is organizers by RIKEN AIP, MLT, Keio University, University of Tokyo, Tokyo Institute of Technology, NTT and MathWorks Japan.  

[<p align="center"> <img src="https://github.com/Machine-Learning-Tokyo/AI-ML-Newsletter/blob/master/images/NeurIPS_Japan_2020.jpeg" width="600" /> </p>](https://neuripsmeetupjapan.github.io/)



📌 Source: [NeurIPS Meetups](https://neuripsconf.medium.com/making-meetups-for-neurips-2020-bbacadaaf6bd)

📌 Source: [NeurIPS Meetup Japan 2020](https://neuripsmeetupjapan.github.io/)


# Grad SLAM

- gradslam is a PyTorch based open-source framework providing differentiable building blocks for SLAM systems.

- SLAM (simultaneous localization and mapping) is the computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. 

- SLAM algorithms are used in navigation, robotic mapping and odometry for virtual reality or augmented reality.
 

[<p align="center"> <img src="https://github.com/Machine-Learning-Tokyo/AI-ML-Newsletter/blob/master/images/gradSLAM.gif" width="600" /> </p>](https://gradslam.github.io/)

📌 Source: [Grad SLAM](https://gradslam.github.io/)

📌 Paper: [∇SLAM: Dense SLAM meets Automatic Differentiation](https://gradslam.github.io/paper.pdf)


# The Language Interpretability Tool (LIT)

- The Language Interpretability Tool (LIT) is an open-source platform for visualization and understanding of NLP models.

- LIT is for researchers and practitioners looking to understand NLP model behavior through a visual, interactive, and extensible tool.

- LIT contains many built-in capabilities but is also customizable, with the ability to add custom interpretability techniques, metrics calculations, counterfactual generators, visualizations, and more.


[<p align="center"> <img src="https://github.com/Machine-Learning-Tokyo/AI-ML-Newsletter/blob/master/images/language_interpretability_tool.gif" width="600" /> </p>](https://pair-code.github.io/lit/)


📌 Source: [The Language Interpretability Tool (LIT)](https://pair-code.github.io/lit/)


# Image Expert Models

- Image Expert Models is a collection of pre-trained image representations that have been tailored for different data distributions.

- 48 models from the Scalable Transfer Learning with Expert Models paper have been added to TFHub, increasing the diversity of pretrained image representations.


[<p align="center"> <img src="https://github.com/Machine-Learning-Tokyo/AI-ML-Newsletter/blob/master/images/image_expert_models.jpeg" width="600" /> </p>](https://tfhub.dev/google/collections/experts/bit/1)


📌 Source: [The Language Interpretability Tool (LIT)](https://tfhub.dev/google/collections/experts/bit/1)

📌 Paper: [Scalable Transfer Learning with Expert Models](https://arxiv.org/abs/2009.13239)


# MinDiff Framework

- MinDiff — a new regularization technique available in the TF Model Remediation library for effectively and efficiently mitigating unfair biases when training ML models.

- Given two sets of examples from our dataset, MinDiff penalizes the model during training for differences in the distribution of scores between the two sets. The less distinguishable the two sets are based on prediction scores, the smaller the penalty that will be applied.

[<p align="center"> <img src="https://github.com/Machine-Learning-Tokyo/AI-ML-Newsletter/blob/master/images/MinDiff.jpeg" width="600" /> </p>](https://www.tensorflow.org/responsible_ai/model_remediation/)




📌 Source: [TF Model Remediation library](https://www.tensorflow.org/responsible_ai/model_remediation/) | [Google AI Blog](https://ai.googleblog.com/2020/11/)


